{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"\"\"https://newsapi.org/v2/everything?\n",
    "language=en\n",
    "&from=2019-10-01\n",
    "&sources=cnbc\n",
    "&apiKey=749e4a9b92e046a386a4420df0de07ee\"\"\")\n",
    "\n",
    "requests.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = Template(\"\"\"\n",
    "https://newsapi.org/v2/everything?\\\n",
    "language=$language\\\n",
    "&from=$from\\\n",
    "&sources=$sources\\\n",
    "&apiKey=$apiKey\\\n",
    "&pageSize=$pageSize\\\n",
    "&page=$page\\\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = url_template.substitute({\"language\": \"en\", \"from\": \"2019-10-01\", \"sources\": \"cnbc\", \n",
    "                               \"apiKey\": \"749e4a9b92e046a386a4420df0de07ee\", \"pageSize\": 30, \"page\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response=response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_response[\"articles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in json_response:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles=[]\n",
    "for entity in json_response:\n",
    "    if(entity=='articles'):\n",
    "        for i in range(0,len(json_response[entity])):\n",
    "            news_articles.append(json_response['articles'][i]['content'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium web driver.\n",
    "driver = webdriver.Chrome(\"C:/chromedriver_win32/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get and store CNBC news articles (text and JSON) in respective directories.\n",
    "\n",
    "def get_news_articles_cnbc (from_date=\"2019-10-01\", api_key=\"749e4a9b92e046a386a4420df0de07ee\", page_size=30, pages=30,\n",
    "                            start_page=1, json_data_dir=\"C:/\", text_data_dir=\"C:/\",\n",
    "                            chrome_driver=\"C:/Users/Administrator/chromedriver_win32/chromedriver\"):\n",
    "    # Create the URL template to query News API.\n",
    "    url_template = Template(\"\"\"\n",
    "    https://newsapi.org/v2/everything?\\\n",
    "    language=$language\\\n",
    "    &from=$from\\\n",
    "    &sources=$sources\\\n",
    "    &apiKey=$apiKey\\\n",
    "    &pageSize=$pageSize\\\n",
    "    &page=$page\\\n",
    "    \"\"\")\n",
    "    # Get the driver object.\n",
    "    driver = webdriver.Chrome(chrome_driver)\n",
    "    \n",
    "    # Iterate over a number of pages.\n",
    "    for page in range(start_page, pages):\n",
    "        url = url_template.substitute({\"language\": \"en\", \"from\": from_date, \"sources\": \"cnbc\", \n",
    "                                       \"apiKey\": api_key, \"pageSize\": page_size, \"page\": page})\n",
    "        response = requests.get(url)\n",
    "        # Iterate over page size, as the number of articles retrieved is = page size.\n",
    "        for article in range(1, page_size):\n",
    "            # File name - Article + underscore + time.\n",
    "            news_article_fname = \"article_\" + time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            # Article - In text and JSON formats.\n",
    "            news_article_text = \"\"\n",
    "            news_article_json = \"\"\n",
    "            # Get article URL. We receive this by parsing the News API response.\n",
    "            news_url = response.json()[\"articles\"][article][\"url\"]\n",
    "            # Print the current status.\n",
    "            print(\"INFO: Fetching article - \" + str(article) + \" of page - \" + str(page) + \". URL - \" + news_url)\n",
    "            # Get page using the Chromium driver.\n",
    "            news_article = driver.get(news_url)\n",
    "            # From this page, get the inner HTML. This gets the entire page as one HTML Document.\n",
    "            news_article_html = driver.find_element_by_xpath(\"//*\").get_attribute(\"innerHTML\")\n",
    "            # Beautiful soup parsed.\n",
    "            news_article_bs = BeautifulSoup(news_article_html, \"lxml\")\n",
    "            # For CNBC, the structure is - one div with id = MainContent, and that consists of divs in class - group.\n",
    "            news_article_divs = news_article_bs.find(id=\"MainContent\").find_all(\"div\", class_=\"group\")\n",
    "            # Iterate over the divs to fetch and concatenate paragraphs.\n",
    "            for div in news_article_divs:\n",
    "                # Get all paragraphs in that div.\n",
    "                news_article_p = div.find_all(\"p\")\n",
    "                for p in news_article_p:\n",
    "                    # Concatenate the text string with the new data from the paragraph tag of the news article.\n",
    "                    news_article_text = news_article_text + \"\\n\" + p.get_text()\n",
    "            # If the text is empty, don't dump to file.\n",
    "            if not (news_article_text.strip()==\"\"):\n",
    "                # Write JSON, using JSON.DUMPS function.\n",
    "                news_article_jfile = open(json_data_dir + \"/\" + news_article_fname + \".json\", \"w+\")\n",
    "                news_article_jfile.write(json.dumps(response.json()[\"articles\"][article]))\n",
    "                news_article_jfile.close()\n",
    "                # Write Text.\n",
    "                news_article_tfile = open(text_data_dir + \"/\" + news_article_fname + \".txt\", \"w+\")\n",
    "                news_article_tfile.write(news_article_text.strip())\n",
    "                news_article_tfile.close()\n",
    "        \n",
    "    # Close Selenium Chrome driver.\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Fetching article - 1 of page - 1. URL - https://www.cnbc.com/2019/10/07/microsoft-upgraded-by-jefferies-we-see-a-large-diversified-business-with-excellent-visibility.html\n"
     ]
    }
   ],
   "source": [
    "get_news_articles_cnbc(json_data_dir=\"C:/Users/Administrator/Documents/GitHub/newsreels/data/News/JSON\",\n",
    "                       text_data_dir=\"C:/Users/Administrator/Documents/GitHub/newsreels/data/News/Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Format\n",
    "TRITTextResponse = TRITResponse.text\n",
    "#print(TRITTextResponse)\n",
    "\n",
    "#Json Format\n",
    "TRITJsonResponse = json.loads(TRITTextResponse)\n",
    "print(TRITJsonResponse)\n",
    "\n",
    "for entity in TRITJsonResponse:\n",
    "    for info in TRITJsonResponse[entity]:\n",
    "        topics={}\n",
    "        geography={}\n",
    "        organizations={}\n",
    "        persons={}\n",
    "        industries={}\n",
    "        currencies={}\n",
    "        market_index={}\n",
    "        \n",
    "        #Topics\n",
    "        if(info=='_typeGroup' and str(TRITJsonResponse[entity][info])=='topics'):\n",
    "            for companyinfo in (TRITJsonResponse[entity]):\n",
    "                if(companyinfo in ['_type','name','confidencelevel','score','relevance','permid']):\n",
    "                    topics[companyinfo]=str(TRITJsonResponse[entity][companyinfo])\n",
    "        if topics:\n",
    "            topics_list.append(topics)\n",
    "\n",
    "        \n",
    "        #Geographical Locations\n",
    "        if((info=='_type' and str(TRITJsonResponse[entity][info]) in ['Country','City','Continent','Region','ProvinceOrState'])):\n",
    "            for companyinfo in (TRITJsonResponse[entity]):\n",
    "                if(companyinfo in ['_type','name','confidencelevel','score','relevance','permid']):\n",
    "                    geography[companyinfo]=str(TRITJsonResponse[entity][companyinfo])\n",
    "                if(companyinfo=='resolutions'):\n",
    "                    if('permid' in TRITJsonResponse[entity][companyinfo][0]):  \n",
    "                        geography['permid']=str(TRITJsonResponse[entity][companyinfo][0]['permid'])\n",
    "                    if('id' in TRITJsonResponse[entity][companyinfo][0]):  \n",
    "                        geography['id']=str(TRITJsonResponse[entity][companyinfo][0]['id'])\n",
    "                    if('score' in TRITJsonResponse[entity][companyinfo][0]):  \n",
    "                        geography['score']=str(TRITJsonResponse[entity][companyinfo][0]['score'])\n",
    "                    if('ticker' in TRITJsonResponse[entity][companyinfo][0]):\n",
    "                        geography['ticker']=str(TRITJsonResponse[entity][companyinfo][0]['ticker'])\n",
    "        if geography:\n",
    "            geographical_list.append(geography)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
